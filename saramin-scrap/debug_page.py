"""í˜ì´ì§€ ì†ŒìŠ¤ ë¶„ì„ìš© ë””ë²„ê·¸ ìŠ¤í¬ë¦½íŠ¸"""
from src.utils.browser import BrowserManager
import time

url = "https://www.saramin.co.kr/zf_user/jobs/list/job-category?page=1&cat_kewd=291%2C238%2C235%2C292&exp_cd=1&search_optional_item=y&search_done=y&panel_count=y&preview=y&isAjaxRequest=0&page_count=50&sort=RL&type=job-category&is_param=1&isSearchResultEmpty=1&isSectionHome=0&searchParamCount=2&tab=job-category"

print("ğŸ” í˜ì´ì§€ ì†ŒìŠ¤ ë¶„ì„ ì‹œì‘...")

with BrowserManager(headless=False) as driver:
    driver.get(url)
    print("â³ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘... (5ì´ˆ)")
    time.sleep(5)

    # HTML ì €ì¥
    html = driver.page_source

    with open('debug_page_source.html', 'w', encoding='utf-8') as f:
        f.write(html)

    print(f"âœ… í˜ì´ì§€ ì†ŒìŠ¤ ì €ì¥ ì™„ë£Œ: debug_page_source.html")
    print(f"ğŸ“Š HTML í¬ê¸°: {len(html):,} bytes")

    # íšŒì‚¬ ê´€ë ¨ ë§í¬ ì°¾ê¸°
    from bs4 import BeautifulSoup
    soup = BeautifulSoup(html, 'lxml')

    # ëª¨ë“  ë§í¬ ì¤‘ company-info í¬í•¨ëœ ê²ƒ ì°¾ê¸°
    all_links = soup.find_all('a', href=True)
    company_links = [a for a in all_links if 'company-info' in a.get('href', '')]

    print(f"\nğŸ“‹ 'company-info' í¬í•¨ ë§í¬: {len(company_links)}ê°œ")

    if company_links:
        print("\nğŸ”— ì²« 5ê°œ íšŒì‚¬ ë§í¬:")
        for idx, link in enumerate(company_links[:5], 1):
            href = link.get('href')
            text = link.get_text(strip=True)
            parent_class = link.parent.get('class', []) if link.parent else []
            print(f"  {idx}. í…ìŠ¤íŠ¸: {text}")
            print(f"     URL: {href}")
            print(f"     ë¶€ëª¨ í´ë˜ìŠ¤: {parent_class}")
            print()

    # ê³µê³  ì•„ì´í…œ ì°¾ê¸°
    print("\nğŸ” ê³µê³  ì•„ì´í…œ êµ¬ì¡° ë¶„ì„:")

    selectors_to_try = [
        ('div.item_recruit', 'ì¼ë°˜ì ì¸ ì±„ìš© ì•„ì´í…œ'),
        ('div[class*="recruit"]', 'recruit í¬í•¨ í´ë˜ìŠ¤'),
        ('div.recruit_info', 'ì±„ìš© ì •ë³´'),
        ('div.list_item', 'ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ'),
        ('.item_recruit', 'ì•„ì´í…œ ì±„ìš©'),
    ]

    for selector, desc in selectors_to_try:
        items = soup.select(selector)
        if items:
            print(f"âœ… '{selector}' ({desc}): {len(items)}ê°œ ë°œê²¬")

            # ì²« ë²ˆì§¸ ì•„ì´í…œì˜ êµ¬ì¡° ì¶œë ¥
            if items:
                first_item = items[0]
                print(f"   ì²« ë²ˆì§¸ ì•„ì´í…œ í´ë˜ìŠ¤: {first_item.get('class', [])}")

                # íšŒì‚¬ëª… ì°¾ê¸°
                company_names = first_item.find_all('a', class_=lambda x: x and 'corp' in str(x).lower())
                if company_names:
                    print(f"   íšŒì‚¬ëª… ë§í¬ ë°œê²¬: {len(company_names)}ê°œ")
                    for cn in company_names[:2]:
                        print(f"     - í´ë˜ìŠ¤: {cn.get('class', [])}")
                        print(f"     - í…ìŠ¤íŠ¸: {cn.get_text(strip=True)}")
        else:
            print(f"âŒ '{selector}' ({desc}): ë°œê²¬ ì•ˆë¨")

    print("\nâœ… ë¶„ì„ ì™„ë£Œ! debug_page_source.html íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
